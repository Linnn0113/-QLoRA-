# **MedCoT-7B: èåˆæ€ç»´é“¾æŠ€æœ¯çš„è½»é‡çº§åŒ»ç–— AI å®è·µ**

**ç¬¬ 32 ç»„è¯¾ç¨‹å¤§ä½œä¸š**ï¼šåŸºäº QLoRA ä¸æ¢¯åº¦ç´¯åŠ ç­–ç•¥ï¼Œåœ¨å•å¡ 11GB æ˜¾å­˜å—é™ç¯å¢ƒä¸‹ï¼Œå®ç°äº† DeepSeek-R1-Distill-Qwen-7B æ¨¡å‹çš„å…¨é‡ LoRA å¾®è°ƒï¼Œèµ‹äºˆæ¨¡å‹åŒ»ç”Ÿçº§çš„ä¸´åºŠè¾¨è¯æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰èƒ½åŠ›ã€‚

## **ğŸ“– é¡¹ç›®ç®€ä»‹ (Introduction)**

æœ¬é¡¹ç›®æ—¨åœ¨è§£å†³åŒ»ç–—å¤§æ¨¡å‹ç§æœ‰åŒ–éƒ¨ç½²ä¸­â€œé«˜æ€§èƒ½â€ä¸â€œä½èµ„æºâ€çš„çŸ›ç›¾ã€‚æˆ‘ä»¬é€‰ç”¨ **DeepSeek-R1-Distill-Qwen-7B** ä½œä¸ºåŸºåº§ï¼Œåˆ©ç”¨ **medical-o1-reasoning-SFT** æ•°æ®é›†æ³¨å…¥ä¸“ä¸šçš„åŒ»å­¦æ¨ç†é€»è¾‘ã€‚

é€šè¿‡å¼•å…¥ **4-bit QLoRA** é‡åŒ–æŠ€æœ¯ä¸ **æ¢¯åº¦ç´¯åŠ  (Gradient Accumulation)** ç­–ç•¥ï¼Œæˆ‘ä»¬æˆåŠŸæ‰“ç ´äº† 11GB æ˜¾å­˜çš„ç‰©ç†ç“¶é¢ˆï¼Œåœ¨å•å¼  RTX 2080 Ti ä¸Šå®Œæˆäº† 3 ä¸ª Epoch çš„æ·±åº¦å¾®è°ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMedCoT-7B åœ¨å¤æ‚ç—…ä¾‹ï¼ˆå¦‚å¤–ç§‘è¼è›„ç––ã€å†…ç§‘è„¾è™šæ³„æ³»ï¼‰çš„è¯Šæ–­ä¸­ï¼Œå…·å¤‡äº†é€»è¾‘ä¸¥å¯†çš„æ€ç»´é“¾æ¨ç†èƒ½åŠ›ï¼Œä¿®æ­£äº†åŸºåº§æ¨¡å‹çš„æ ‡ç­¾åç½®é—®é¢˜ã€‚

## **ğŸŒŸ æ ¸å¿ƒç‰¹æ€§ (Features)**

* **ä½èµ„æºæè‡´ä¼˜åŒ–**ï¼šé€šè¿‡ Batch Size=1 \+ Gradient Accumulation=16 ç­–ç•¥ï¼Œåœ¨ 11GB æ˜¾å­˜ä¸‹å®ç°äº†ç­‰æ•ˆ Batch Size 16 çš„è®­ç»ƒï¼Œæ—  OOM æº¢å‡ºã€‚  
* **æ€ç»´é“¾ (CoT) å¯¹é½**ï¼šæ¨¡å‹ä¸ä»…è¾“å‡ºè¯Šæ–­ç»“æœï¼Œè¿˜èƒ½åœ¨ \<think\> æ ‡ç­¾å†…å±•ç¤ºå®Œæ•´çš„ç—…ç†åˆ†æä¸é‰´åˆ«è¯Šæ–­è¿‡ç¨‹ã€‚  
* **é«˜æ•ˆè®­ç»ƒ**ï¼šé›†æˆ Unsloth åŠ é€Ÿæ¡†æ¶ï¼Œè®­ç»ƒæ•ˆç‡æå‡çº¦ 2.3 å€ï¼Œæ€»è®­ç»ƒæ—¶é•¿çº¦ 11 å°æ—¶ã€‚  
* **ä¸´åºŠé€»è¾‘ä¿®æ­£**ï¼šæœ‰æ•ˆè§£å†³äº†é€šç”¨æ¨¡å‹åœ¨é•¿å°¾ç—…ç§ï¼ˆå¦‚â€œè¼è›„ç––â€ï¼‰ä¸Šè¯¯è¯Šä¸ºé«˜é¢‘è¯ï¼ˆå¦‚â€œç–³ç§¯â€ï¼‰çš„é—®é¢˜ã€‚

## **ğŸ“‚ ä»“åº“ç»“æ„ (Directory Structure)**

.  
â”œâ”€â”€ README.md               \# é¡¹ç›®è¯´æ˜æ–‡æ¡£  
â”œâ”€â”€ requirements.txt        \# ç¯å¢ƒä¾èµ–åˆ—è¡¨  
â”œâ”€â”€ src/                    \# æ ¸å¿ƒä»£ç   
â”‚   â”œâ”€â”€ process.py          \# æ•°æ®æ¸…æ´—ä¸ CoT æ ¼å¼åŒ–è„šæœ¬  
â”‚   â””â”€â”€ med\_app.py          \# Streamlit å‰ç«¯æ¼”ç¤ºåº”ç”¨  
â”œâ”€â”€ scripts/                \# è¿è¡Œè„šæœ¬  
â”‚   â””â”€â”€ run\_train.sh        \# ä¸€é”®å¤ç°è®­ç»ƒè„šæœ¬  
â”œâ”€â”€ data/                   \# æ•°æ®é›†å­˜æ”¾ç›®å½•  
â”‚   â”œâ”€â”€ dataset\_info.json   \# æ•°æ®é›†æ³¨å†Œé…ç½®  
â”‚   â””â”€â”€ medical\_o1\_sft.json \# (éœ€è‡ªè¡Œä¸‹è½½) åŸå§‹æ•°æ®é›†  
â””â”€â”€ results/                \# å®éªŒç»“æœä¸å›¾è¡¨  
    â”œâ”€â”€ final\_loss.png      \# è®­ç»ƒ Loss æ”¶æ•›æ›²çº¿  
    â”œâ”€â”€ final\_ppl.png       \# å›°æƒ‘åº¦å˜åŒ–æ›²çº¿  
    â”œâ”€â”€ final\_lr.png        \# å­¦ä¹ ç‡è°ƒåº¦æ›²çº¿  
    â””â”€â”€ comparison/         \# å¾®è°ƒå‰åç—…ä¾‹å›ç­”å¯¹æ¯”å›¾

## **ğŸ› ï¸ ç¯å¢ƒå®‰è£… (Installation)**

æ¨èä½¿ç”¨ Conda åˆ›å»ºç‹¬ç«‹ç¯å¢ƒã€‚

**ç¡¬ä»¶è¦æ±‚**ï¼š

* **GPU**: NVIDIA RTX 2080 Ti (11GB) æˆ–æ›´é«˜é…ç½® (æ”¯æŒ CUDA 11.8+)  
* **RAM**: 16GB+  
* **Disk**: è‡³å°‘ 50GB å¯ç”¨ç©ºé—´ (ç”¨äºå­˜æ”¾æ¨¡å‹æƒé‡å’Œæ•°æ®é›†)

\# 1\. åˆ›å»ºç¯å¢ƒ  
conda create \-n medcot python=3.10 \-y  
conda activate medcot

\# 2\. å®‰è£… PyTorch (å…¼å®¹ CUDA 11.8/12.1)  
pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 \--index-url \[https://download.pytorch.org/whl/cu121\](https://download.pytorch.org/whl/cu121)

\# 3\. å®‰è£…é¡¹ç›®ä¾èµ– (åŒ…å« Unsloth å’Œ LLaMA-Factory)  
pip install \-r requirements.txt

## **ğŸ”¬ æ•°æ®é›†å‡†å¤‡ (Data Preparation)**

1. ä¸‹è½½ **medical-o1-reasoning-SFT** æ•°æ®é›†ã€‚  
2. å°†æ•°æ®é›†æ–‡ä»¶é‡å‘½åä¸º medical\_o1\_sft\_Chinese.json å¹¶æ”¾ç½®åœ¨ data/ ç›®å½•ä¸‹ã€‚  
3. ç¡®ä¿ data/dataset\_info.json ä¸­å·²æ³¨å†Œå¦‚ä¸‹ä¿¡æ¯ï¼š

"medical-o1-reasoning-SFT": {  
  "file\_name": "medical\_o1\_sft\_Chinese.json",  
  "columns": {  
    "prompt": "Question",  
    "query": "",  
    "response": "Response"  
  }  
}

## **ğŸš€ è®­ç»ƒå¤ç° (Reproduction)**

æˆ‘ä»¬æä¾›äº†ç²¾ç¡®çš„å¤ç°è„šæœ¬ã€‚è¯¥é…ç½®ä¸“ä¸º **11GB æ˜¾å­˜** ä¼˜åŒ–ï¼Œè‹¥æ˜¾å­˜æ›´å¤§å¯é€‚å½“è°ƒæ•´ Batch Sizeã€‚

**è¿è¡Œå‘½ä»¤ï¼š**

bash scripts/run\_train.sh

**run\_train.sh çš„å…·ä½“å†…å®¹ (Exact Command)ï¼š**

\#\!/bin/bash

\# å¼€å¯æ˜¾å­˜ç¢ç‰‡æ•´ç†ï¼Œé˜²æ­¢ OOM  
export PYTORCH\_CUDA\_ALLOC\_CONF=expandable\_segments:True

\# å¯åŠ¨è®­ç»ƒ  
CUDA\_VISIBLE\_DEVICES=0 llamafactory-cli train \\  
    \--stage sft \\  
    \--do\_train True \\  
    \--model\_name\_or\_path deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \\  
    \--dataset medical-o1-reasoning-SFT \\  
    \--template deepseek \\  
    \--finetuning\_type lora \\  
    \--lora\_target all \\  
    \--output\_dir results/MedCoT-7B-Final \\  
    \--overwrite\_cache \\  
    \--overwrite\_output\_dir \\  
    \--cutoff\_len 2048 \\  
    \--preprocessing\_num\_workers 16 \\  
    \--per\_device\_train\_batch\_size 1 \\  
    \--gradient\_accumulation\_steps 16 \\  
    \--lr\_scheduler\_type cosine \\  
    \--logging\_steps 10 \\  
    \--save\_steps 500 \\  
    \--learning\_rate 5e-5 \\  
    \--num\_train\_epochs 3.0 \\  
    \--quantization\_bit 4 \\  
    \--plot\_loss True \\  
    \--fp16 True \\  
    \--seed 42

* **æ³¨**ï¼š--seed 42 ç”¨äºå›ºå®šéšæœºç§å­ä»¥ä¿è¯ç»“æœå¯å¤ç°ã€‚  
* **æ³¨**ï¼š--per\_device\_train\_batch\_size 1 é…åˆ \--gradient\_accumulation\_steps 16 å®ç°äº†ç­‰æ•ˆ Batch Size \= 16ï¼Œæ˜¯è§£å†³ 2080 Ti æ˜¾å­˜æº¢å‡ºçš„å…³é”®ã€‚

## **ğŸ“Š å®éªŒç»“æœ (Results)**

æ¨¡å‹åœ¨ 3 ä¸ª Epoch åè¾¾åˆ°æ”¶æ•›ï¼Œå…·ä½“æŒ‡æ ‡å¦‚ä¸‹ï¼š

| æŒ‡æ ‡ (Metrics) | æ•°å€¼ (Value) | è¯´æ˜ |  
| Training Loss | 1.4623 | æŸå¤±å‡½æ•°å¹³ç¨³ä¸‹é™ï¼Œè¡¨æ˜æ¨¡å‹å……åˆ†æ‹Ÿåˆæ€ç»´é“¾æ•°æ®ã€‚ |  
| Perplexity (PPL) | 4.31 | å›°æƒ‘åº¦æ˜¾è‘—é™ä½ï¼Œå¯¹åŒ»ç–—æœ¯è¯­çš„é¢„æµ‹æ›´ç²¾å‡†ã€‚ |  
| Training Time | \~11h | å•å¡ 2080 Ti é«˜æ•ˆå®Œæˆã€‚ |

### **è®­ç»ƒæ›²çº¿å›¾**

*(è¯·åœ¨ results/ ç›®å½•ä¸‹æŸ¥çœ‹è¯¦ç»†å¤§å›¾)*

## **ğŸ©º æ¨ç†ä¸æ¼”ç¤º (Inference & Demo)**

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨ Streamlit å¯åŠ¨å¸¦æœ‰æ€ç»´é“¾å±•ç¤ºçš„ Web ç•Œé¢ï¼š

\# 1\. å¯åŠ¨ API åç«¯ (åŠ è½½å¾®è°ƒåçš„ Adapter)  
CUDA\_VISIBLE\_DEVICES=0 API\_PORT=8000 llamafactory-cli api \\  
    \--model\_name\_or\_path deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \\  
    \--adapter\_name\_or\_path results/MedCoT-7B-Final \\  
    \--template deepseek \\  
    \--finetuning\_type lora \\  
    \--quantization\_bit 4

\# 2\. å¯åŠ¨å‰ç«¯é¡µé¢ (å¦å¼€ç»ˆç«¯)  
streamlit run src/med\_app.py

### **å…¸å‹æ¡ˆä¾‹å¯¹æ¯”**

**è¾“å…¥**ï¼š1å²å¹¼å„¿ï¼Œå¤å­£å¤´çš®å‡ºç°å¤šå¤„å°ç»“èŠ‚ï¼Œæºƒç ´æµè„“ï¼Œçš®ä¸‹æœ‰ç©ºæ´ã€‚

* **å¾®è°ƒå‰**ï¼šè¯¯è¯Šä¸ºâ€œç–³ç§¯â€æˆ–â€œç—„è…®â€ï¼Œé€»è¾‘æ··ä¹±ã€‚  
* **å¾®è°ƒå**ï¼š\<think\> æ ‡ç­¾å†…å‡†ç¡®è¯†åˆ«â€œå¤å­£æ¹¿çƒ­â€ã€â€œçš®ä¸‹ç©ºæ´â€ç‰¹å¾ï¼Œ**ç¡®è¯Šä¸ºâ€œè¼è›„ç––â€**ã€‚

## **ğŸ“ å¼•ç”¨ä¸è‡´è°¢ (Citation)**

æœ¬é¡¹ç›®åŸºäº [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) å’Œ [Unsloth](https://github.com/unslothai/unsloth) æ„å»ºã€‚æ„Ÿè°¢ FreedomIntelligence æä¾›çš„å¼€æºåŒ»ç–—æ•°æ®é›†ã€‚

*Created by Group 32 for the Deep Learning Course Project.*